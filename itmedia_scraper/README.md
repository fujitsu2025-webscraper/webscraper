# ITmedia AI スクレイパー

[ITmedia AI](https://www.itmedia.co.jp/aiplus/)から記事を抽出するために設計されたウェブスクレイピングツールです。

## 機能

* [ITmedia AIウェブサイト](https://www.itmedia.co.jp/aiplus/)から記事をスクレイピング
* Shift-JISエンコーディングを適切に処理
* 記事のタイトル、URL、公開日、内容を抽出
* 記事をカスタムビジネスカテゴリに分類
* OpenAIのAPIを使用して記事内容の簡潔な要約を生成
* 重複URLのスクレイピングを防止（複数ページにわたっても）
* データをタイムスタンプ付きでJSONまたはCSVファイルに保存
* サーバーに配慮した、リクエスト間の設定可能な遅延を含む
* キーワードとカテゴリによるフィルタリングオプションを提供
* タイムスタンプ付きディレクトリに出力ファイルを整理
* 設定可能なログレベルを持つ詳細なロギング
* 実行時間と進行状況の追跡
* 記事に言及されている企業名の抽出

## プロジェクト構造

```text
webscraper/
├── README.md                  # プロジェクトの説明
├── requirements.txt           # 必要なパッケージ
├── itmedia_main.py            # メインスクリプト（エントリーポイント）
├── .env                       # 環境変数
├── output/                    # 出力ディレクトリ
└── itmedia/                   # モジュールディレクトリ
    ├── __init__.py            # パッケージ初期化
    ├── scraper.py             # スクレイパーのコアクラス
    ├── utils.py               # ユーティリティ関数
    └── llm.py                 # LLM関連の機能
```

## 要件

* Python 3.6+
* `requirements.txt`にリストされている必要なパッケージ
* OpenAI APIキー（オプション、デフォルトキーは埋め込まれています）

## インストール

1. 必要なパッケージをインストールします：

```bash
pip install -r requirements.txt
```

## 使用方法

スクレイパーを実行します：

```bash
python itmedia_main.py
```

### コマンドラインオプション

スクレイパーはいくつかのコマンドラインオプションをサポートしています：

```text
usage: itmedia_main.py [-h] [--pages PAGES] [--delay DELAY] [--output OUTPUT] 
                      [--metadata-only] [--keyword KEYWORD] [--category CATEGORY] 
                      [--openai-api-key OPENAI_API_KEY] [--disable-llm]
                      [--output-dir OUTPUT_DIR] [--log-level {DEBUG,INFO,WARNING,ERROR,CRITICAL}]
                      [--recent-archives RECENT_ARCHIVES] [--start-from-month START_FROM_MONTH]
                      [--max-articles MAX_ARTICLES]
```

### 例

```bash
# 基本的な使用法（デフォルトで最近3ヶ月分のアーカイブをスクレイピング）
python itmedia_main.py

# 3ページ分スクレイピング
python itmedia_main.py --pages 3

# メタデータのみをスクレイピング（高速）
python itmedia_main.py --metadata-only

# 特定のキーワードを含む記事のみをスクレイピング
python itmedia_main.py --keyword "ChatGPT"

# 特定のカテゴリの記事のみをスクレイピング
python itmedia_main.py --category "AI技術基盤"

# 最大5件の記事のみをスクレイピング
python itmedia_main.py --max-articles 5

# 2025年1月のアーカイブから最大10件の記事をスクレイピング
python itmedia_main.py --archive-month 2501 --max-articles 10

# 最近6ヶ月分のアーカイブから最大20件の記事をスクレイピング
python itmedia_main.py --recent-archives 6 --max-articles 20
```

## 出力形式

スクレイパーは2つの形式でデータを出力できます：

### JSON形式

記事オブジェクトの配列を含むJSONファイル。各記事オブジェクトには以下が含まれます：

* `title`: 記事のタイトル
* `url`: 記事のURL
* `publication_date`: YYYY-MM-DD形式の公開日
* `custom_category`: 事前定義されたビジネスカテゴリの1つに分類
* `content`: 要約された記事内容（約500文字）
* `companies`: 記事内で言及されている企業名（複数の場合は改行で区切られる）

### CSV形式

記事ごとに1行のCSVファイル。列にはJSON形式で利用可能なすべてのフィールドが含まれ、スプレッドシートアプリケーションやデータ分析ツールへの取り込みが容易です。

## 出力ディレクトリ構造

デフォルトでは、スクレイパーは現在の作業ディレクトリに`output`ディレクトリを作成します。このディレクトリ内に、各スクレイピングセッション用のタイムスタンプ付きサブディレクトリ（例：`20250325_215930`）を作成します。この構造により、複数のスクレイピングセッションを整理するのに役立ちます。

各セッションディレクトリには以下が含まれます：

* スクレイピングされたデータファイル（JSONとCSV）
* スクレイピングプロセスに関する情報を含む詳細なログファイル（`scraper.log`）

`--output-dir`オプションを使用して、カスタム出力ディレクトリを指定できます。

## ロギング

スクレイパーには、スクレイピングプロセスに関する情報を記録する包括的なロギングシステムが含まれています。ログはコンソールと出力ディレクトリ内のログファイルの両方に書き込まれます。

`--log-level`オプションを使用して、ログの詳細度を制御できます：

* `DEBUG`: 詳細なデバッグ情報
* `INFO`: スクレイピングプロセスに関する一般的な情報（デフォルト）
* `WARNING`: 警告と潜在的な問題
* `ERROR`: エラーメッセージ
* `CRITICAL`: スクレイパーの機能を妨げる重大なエラー

ログファイル（`scraper.log`）には、タイムスタンプ、ログレベル、スクレイピングプロセスの各ステップに関する詳細なメッセージが含まれ、進行状況の追跡や問題の診断が容易になります。

## ビジネスカテゴリ

記事は自動的に以下のビジネスカテゴリの1つに分類されます：

* `業務効率化・自動化` (Business Efficiency/Automation): 企業や組織におけるAI活用、業務プロセスの効率化、自動化に関する内容
* `研究動向` (Research Trends): AI研究、論文、新しいアルゴリズム、モデル開発などの学術的・技術的進展
* `市場・ビジネス動向` (Market/Business Trends): AI市場の動向、企業戦略、投資、経済的影響に関する内容
* `製品・サービス` (Products/Services): 新しいAI製品やサービスの発表、リリース、機能に関する内容
* `セキュリティ・倫理` (Security/Ethics): AIのセキュリティリスク、倫理的問題、プライバシー、バイアスなどに関する内容
* `教育・人材育成` (Education/Human Resources): AI教育、スキル開発、人材育成、トレーニングに関する内容
* `AI技術基盤` (AI Infrastructure): GPU、計算資源、ハードウェア、基盤技術、アーキテクチャに関する内容
* `社会実装・応用` (Social Implementation): AIの実社会での応用事例、導入事例、ユースケースに関する内容
* `政策・規制` (Policy/Regulation): AI関連の政策、法規制、ガバナンス、国家戦略に関する内容

分類は2つの方法で実行されます：

1. **LLMベースの分類（デフォルト）**: スクレイパーはOpenAIのAPIを使用して記事の全文を分析し、最も適切なカテゴリを決定します。これにより、記事全体のコンテキストに基づいたより正確な分類が可能になります。

2. **キーワードベースの分類（フォールバック）**: LLMが無効化されているか、エラーが発生した場合、スクレイパーはキーワードベースのアプローチにフォールバックし、記事のタイトルを分析してカテゴリを決定します。

## LLM要約と分類

デフォルトでは、スクレイパーはOpenAIのAPIを3つの目的で使用します：

1. **内容要約**: LLMが記事URLに直接アクセスして内容を読み取り、要約することで、高品質な記事内容の要約を生成します。

2. **記事分類**: 記事の全文を分析して、事前定義されたリストから最も適切なビジネスカテゴリを決定します。

3. **企業名抽出**: 記事の内容から言及されている企業名を抽出します。複数の企業が言及されている場合は、改行で区切られます。

これらのLLM機能を使用したくない場合（APIコストを避けるためや、プライバシー上の理由など）、`--disable-llm`オプションで無効にできます。この場合、スクレイパーは内容の基本的なテキスト抽出とキーワードベースの分類にフォールバックします。

## 法的通知

このツールは責任を持って、ITmediaの利用規約に従って使用してください。ウェブスクレイピングはウェブサイトの利用規約に違反する可能性があるため、このツールを広範囲に使用する前に許可を得ていることを確認してください。
